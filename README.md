# Code-Agent

Este repositorio contiene los archivos utilizados para implementar y evaluar un agente de software con modelos LLM usando [SWE-Agent](https://github.com/princeton-nlp/SWE-agent) y [SWE-Bench](https://github.com/princeton-nlp/SWE-bench).

## Objetivo

El prop칩sito de este proyecto es automatizar la resoluci칩n de *issues* de GitHub mediante un agente que interact칰a con un modelo LLM (como Qwen) fine-tuneado para generar parches efectivos. Se eval칰a el rendimiento del modelo utilizando el benchmark oficial de SWE-Bench.

## Contenido del repositorio

- **`ollama-finetune.py`**: Script en Python para subir un modelo fine-tuneado a Modal utilizando Ollama.
- **`ollama_modal.py`**: Script en Python para alojar el modelo base en Modal y configurar su endpoint para ser utilizado por SWE-Agent.
- **`qwen-finetune.yaml`**: Archivo de configuraci칩n en YAML para que SWE-Agent utilice el modelo desplegado en Modal (incluye par치metros como `api_base`, `model_name`, y `parse_function`).
- **`README.md`**: Este archivo.
- **`Google Colab del Fine-Tuning`**: El fine-tuning fue realizado en Google Colab. Aqu칤 puedes ver el notebook donde se entren칩 el modelo:
  [游댕 Google Colab - Fine-tuning Qwen con Unsloth](https://colab.research.google.com/) *(agrega aqu칤 el enlace directo a tu notebook si ya lo publicaste)*

## Herramientas utilizadas

- **[SWE-Agent](https://github.com/princeton-nlp/SWE-agent)**: Herramienta para ejecutar agentes LLM que resuelven issues en repositorios de GitHub mediante generaci칩n de parches automatizados.
- **[SWE-Bench](https://github.com/princeton-nlp/SWE-bench)**: Benchmark utilizado para medir el rendimiento del agente, con m칰ltiples tareas de evaluaci칩n y m칠tricas como "fix coverage" y "pass@1".
- **[Modal](https://modal.com/)**: Plataforma utilizada para alojar tanto el modelo base como el modelo fine-tuneado de manera eficiente.
- **[Ollama](https://ollama.com/)**: Herramienta que permite trabajar con modelos en formato GGUF y exponerlos v칤a API compatible con SWE-Agent.
- **[Unsloth](https://github.com/unslothai/unsloth)**: Librer칤a utilizada para realizar el fine-tuning del modelo (en este caso Qwen) de forma eficiente, incluso en entornos como Google Colab.

## C칩mo comenzar

1. Realiza el fine-tuning de tu modelo siguiendo el notebook en Colab.
2. Usa `ollama-finetune.py` para cargar tu modelo fine-tuneado a Modal.
3. Usa `ollama_modal.py` si necesitas alojar un modelo base.
4. Configura tu agente con `qwen-finetune.yaml`.
5. Eval칰a el desempe침o con SWE-Bench (por ejemplo usando `run_evaluation`).

---

Si necesitas ayuda con la configuraci칩n o ejecuci칩n, puedes abrir un *issue* en este repositorio.

## Video:
- https://www.youtube.com/watch?v=-G_p4gRiJnw&feature=youtu.be
